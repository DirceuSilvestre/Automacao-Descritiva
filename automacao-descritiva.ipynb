{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11082128,"sourceType":"datasetVersion","datasetId":6784624}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Descriptive Statistics Automation Project","metadata":{}},{"cell_type":"markdown","source":"The project aims to automate whatever is possible within my knowledge, program tools to assist in data processing and analysis, practice knowledge and seek more.\n\nClick run all and go to the last cell to download the descriptive analysis PDF","metadata":{}},{"cell_type":"markdown","source":"# Environment preparation","metadata":{}},{"cell_type":"markdown","source":"instala bibliotecas\n\nchama as bibliotecas\n\nprepara o pdf\n\nfaz a leitura dos dados (csv, xls, json)\n\nfaz a classificação dos tipos de dados\n\nfaz a limpeza dos dados\n\nativa o conjunto de operações de cada tipo, qualitativo, quantitativo\n\nreune tudo em um pdf e salva com download\n","metadata":{}},{"cell_type":"markdown","source":"## Install libraries","metadata":{}},{"cell_type":"code","source":"%pip install weasyprint\n%pip install -U kaleido","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:39.704578Z","iopub.execute_input":"2025-04-13T00:13:39.704991Z","iopub.status.idle":"2025-04-13T00:13:47.554234Z","shell.execute_reply.started":"2025-04-13T00:13:39.704962Z","shell.execute_reply":"2025-04-13T00:13:47.552827Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: weasyprint in /usr/local/lib/python3.11/dist-packages (65.0)\nRequirement already satisfied: pydyf>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.11.0)\nRequirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (1.17.1)\nRequirement already satisfied: tinyhtml5>=2.0.0b1 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (2.0.0)\nRequirement already satisfied: tinycss2>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (1.4.0)\nRequirement already satisfied: cssselect2>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.8.0)\nRequirement already satisfied: Pyphen>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.17.2)\nRequirement already satisfied: Pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (11.1.0)\nRequirement already satisfied: fonttools>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (4.56.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=0.6->weasyprint) (2.22)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from cssselect2>=0.8.0->weasyprint) (0.5.1)\nRequirement already satisfied: brotli>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (1.1.0)\nRequirement already satisfied: zopfli>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (0.2.3.post1)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: kaleido in /usr/local/lib/python3.11/dist-packages (0.2.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"import plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.io as pio\nimport seaborn as sns\nimport plotly as plt\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport base64\nimport io\n\nfrom sklearn.feature_selection import mutual_info_classif, mutual_info_regression\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy.stats import spearmanr, pearsonr\nfrom scipy.stats import gaussian_kde\nfrom weasyprint import HTML\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.556258Z","iopub.execute_input":"2025-04-13T00:13:47.556588Z","iopub.status.idle":"2025-04-13T00:13:47.564501Z","shell.execute_reply.started":"2025-04-13T00:13:47.556559Z","shell.execute_reply":"2025-04-13T00:13:47.563419Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"warnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.565608Z","iopub.execute_input":"2025-04-13T00:13:47.565921Z","iopub.status.idle":"2025-04-13T00:13:47.591152Z","shell.execute_reply.started":"2025-04-13T00:13:47.565898Z","shell.execute_reply":"2025-04-13T00:13:47.589942Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"## Prepare PDF","metadata":{}},{"cell_type":"code","source":"class PDFGenerator:\n    def __init__(self):\n        self.html_content = \"\"\n        self.image_count = 0\n        self.level = 1\n    \n    def add_header(self, text):\n        self.html_content += f\"<h{self.level}>{text}</h{self.level}>\"\n    \n    def add_text(self, text):\n        self.html_content += f\"<p>{text}</p>\"\n\n    def add_break(self):\n        self.html_content += f\"<br />\"\n    \n    def add_dataframe(self, df, style=False):\n        if style:\n            self.html_content += df.style.set_table_styles([\n                {'selector': 'th', 'props': [('background-color', '#40466e'), ('color', 'white')],\n                 'selector': 'td', 'props': [('border', '1px solid #ddd')]}\n            ]).hide(axis='index').to_html()\n        else:\n            self.html_content += df.to_html()\n    \n    def add_image(self, image_path, max_width=600, max_height=800, quality=100, spacing_before=10, spacing_after=10, margin_right=10, margin_left=10):\n        \"\"\"\n        Adiciona imagem com espaçamento controlado\n        \n        Parâmetros adicionais:\n        - spacing_before: Espaço antes da imagem (em pixels)\n        - spacing_after: Espaço após a imagem (em pixels)\n        \"\"\"\n        self.image_count += 1\n        \n        with Image.open(image_path) as img:\n            width, height = img.size\n            ratio = min(max_width/width, max_height/height)\n            new_size = (int(width*ratio), int(height*ratio))\n            img = img.resize(new_size, Image.Resampling.LANCZOS)\n            \n            img_bytes = io.BytesIO()\n            img.save(img_bytes, format='PNG', quality=quality)\n            img_bytes.seek(0)\n            img_data = base64.b64encode(img_bytes.read()).decode('utf-8')\n        \n        # Adiciona espaçamento antes e depois da imagem\n        self.html_content += (\n            f'<div style=\"margin-top: {spacing_before}px {margin_right}px {spacing_after}px {margin_left}px; text-align:center;\">'\n            f'<img src=\"data:image/png;base64,{img_data}\" '\n            f'style=\"max-width:{max_width}px; max-height:{max_height}px; width:auto; height:auto;\"/>'\n            f'</div>'\n        )\n    \n    def generate_pdf(self, filename=\"report.pdf\"):\n        # Usando WeasyPrint para melhor qualidade (instale com pip install weasyprint)\n        HTML(string=self.html_content).write_pdf(filename)\n        return filename\n\n# Instancie o gerador\npdf_gen = PDFGenerator()\n\n\n# Célula com texto\n# pdf_gen.add_header(\"Análise Exploratória de Dados\")\n# pdf_gen.add_text(\"Esta é uma análise completa dos dados de vendas do trimestre.\")\n\n# Célula com DataFrame\n# pdf_gen.add_dataframe(df, style=True)\n\n# Célula com visualização\n# import matplotlib.pyplot as plt\n# plt.bar(df['Mês'], df['Vendas'])\n# plt.title('Vendas por Mês')\n# plt.savefig('vendas.png')\n# plt.close()\n# pdf_gen.add_image('vendas.png')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.593638Z","iopub.execute_input":"2025-04-13T00:13:47.594005Z","iopub.status.idle":"2025-04-13T00:13:47.617070Z","shell.execute_reply.started":"2025-04-13T00:13:47.593978Z","shell.execute_reply":"2025-04-13T00:13:47.615921Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"## Read Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/chocolate-sales/Chocolate Sales.csv') #kaggle/input/folder/archive.csv\n\n# .read_excel('arquivo.xlsx')\n# .read_json('arquivo.json')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.618417Z","iopub.execute_input":"2025-04-13T00:13:47.618695Z","iopub.status.idle":"2025-04-13T00:13:47.659181Z","shell.execute_reply.started":"2025-04-13T00:13:47.618674Z","shell.execute_reply":"2025-04-13T00:13:47.657920Z"}},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":"## Classification Data","metadata":{}},{"cell_type":"code","source":"pdf_gen.add_header(\"Visualização e Conferência do Dataset\")\n\npdf_gen.add_dataframe(df[0:6], style=True)\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.660389Z","iopub.execute_input":"2025-04-13T00:13:47.660933Z","iopub.status.idle":"2025-04-13T00:13:47.677554Z","shell.execute_reply.started":"2025-04-13T00:13:47.660896Z","shell.execute_reply":"2025-04-13T00:13:47.676554Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"     Sales Person    Country              Product       Date    Amount  \\\n0  Jehu Rudeforth         UK      Mint Chip Choco  04-Jan-22   $5,320    \n1     Van Tuxwell      India        85% Dark Bars  01-Aug-22   $7,896    \n2    Gigi Bohling      India  Peanut Butter Cubes  07-Jul-22   $4,501    \n3    Jan Morforth  Australia  Peanut Butter Cubes  27-Apr-22  $12,726    \n4  Jehu Rudeforth         UK  Peanut Butter Cubes  24-Feb-22  $13,685    \n\n   Boxes Shipped  \n0            180  \n1             94  \n2             91  \n3            342  \n4            184  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sales Person</th>\n      <th>Country</th>\n      <th>Product</th>\n      <th>Date</th>\n      <th>Amount</th>\n      <th>Boxes Shipped</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jehu Rudeforth</td>\n      <td>UK</td>\n      <td>Mint Chip Choco</td>\n      <td>04-Jan-22</td>\n      <td>$5,320</td>\n      <td>180</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Van Tuxwell</td>\n      <td>India</td>\n      <td>85% Dark Bars</td>\n      <td>01-Aug-22</td>\n      <td>$7,896</td>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Gigi Bohling</td>\n      <td>India</td>\n      <td>Peanut Butter Cubes</td>\n      <td>07-Jul-22</td>\n      <td>$4,501</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jan Morforth</td>\n      <td>Australia</td>\n      <td>Peanut Butter Cubes</td>\n      <td>27-Apr-22</td>\n      <td>$12,726</td>\n      <td>342</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jehu Rudeforth</td>\n      <td>UK</td>\n      <td>Peanut Butter Cubes</td>\n      <td>24-Feb-22</td>\n      <td>$13,685</td>\n      <td>184</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"pdf_gen.add_text(f\"\"\"Tipo inicial dos dados: \\n \n{df.dtypes}\n\\n\"\"\".replace(\"\\n\", \"<br />\"))\n\nprint(df.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.678748Z","iopub.execute_input":"2025-04-13T00:13:47.679827Z","iopub.status.idle":"2025-04-13T00:13:47.699810Z","shell.execute_reply.started":"2025-04-13T00:13:47.679789Z","shell.execute_reply":"2025-04-13T00:13:47.698811Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Sales Person     object\nCountry          object\nProduct          object\nDate             object\nAmount           object\nBoxes Shipped     int64\ndtype: object\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"Temos 4 tipos de dados\n\nQualitativos Nominais e Ordinais - string\n\nQuantitativos Discretos e Continuos - int e float\n\ne também o tipo especial data","metadata":{}},{"cell_type":"code","source":"# limpeza de símbolos monetários\n\ndf['Amount'] = df['Amount'].str.extract(r'(\\d+[\\.,]?\\d*)')[0] \\\n                               .str.replace(',', '.') \\\n                               .astype(float)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.701055Z","iopub.execute_input":"2025-04-13T00:13:47.701547Z","iopub.status.idle":"2025-04-13T00:13:47.732280Z","shell.execute_reply.started":"2025-04-13T00:13:47.701513Z","shell.execute_reply":"2025-04-13T00:13:47.731244Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"# transformação em data\n\ndf['Date'] = pd.to_datetime(df['Date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.733722Z","iopub.execute_input":"2025-04-13T00:13:47.734103Z","iopub.status.idle":"2025-04-13T00:13:47.810364Z","shell.execute_reply.started":"2025-04-13T00:13:47.734071Z","shell.execute_reply":"2025-04-13T00:13:47.809500Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"df = df.convert_dtypes(convert_string=True, convert_floating=False, convert_integer=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.813913Z","iopub.execute_input":"2025-04-13T00:13:47.814210Z","iopub.status.idle":"2025-04-13T00:13:47.820823Z","shell.execute_reply.started":"2025-04-13T00:13:47.814189Z","shell.execute_reply":"2025-04-13T00:13:47.819723Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"pdf_gen.add_dataframe(df[0:3], style=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.822078Z","iopub.execute_input":"2025-04-13T00:13:47.822469Z","iopub.status.idle":"2025-04-13T00:13:47.846314Z","shell.execute_reply.started":"2025-04-13T00:13:47.822424Z","shell.execute_reply":"2025-04-13T00:13:47.845427Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"pdf_gen.add_text(f'''Verificando se, após a transformação os tipos dos dados correspondem aos da tabela: \\n\n{df.dtypes}\n\\n'''.replace(\"\\n\", \"<br />\"))\n\n\nprint(f'''Verificando se, após a transformação os tipos dos dados correspondem aos da tabela: \\n\n\n{df.dtypes}''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.847349Z","iopub.execute_input":"2025-04-13T00:13:47.847670Z","iopub.status.idle":"2025-04-13T00:13:47.871453Z","shell.execute_reply.started":"2025-04-13T00:13:47.847648Z","shell.execute_reply":"2025-04-13T00:13:47.870409Z"}},"outputs":[{"name":"stdout","text":"Verificando se, após a transformação os tipos dos dados correspondem aos da tabela: \n\n\nSales Person     string[python]\nCountry          string[python]\nProduct          string[python]\nDate             datetime64[ns]\nAmount                  float64\nBoxes Shipped             int64\ndtype: object\n","output_type":"stream"}],"execution_count":58},{"cell_type":"markdown","source":"## Cleaning Data","metadata":{}},{"cell_type":"code","source":"linha = df.shape[0]\n\ncoluna = df.shape[1]\n\ndf.dropna(inplace=True)\n\nlinha1 = df.shape[0]\n\ncoluna1 = df.shape[1]\n\n\npdf_gen.add_text(f'Antes da limpeza de dados faltantes, o data set tinha {linha} linhas e {coluna} colunas. A limpeza retirou {linha - linha1} linhas e {coluna - coluna1} colunas, ficando o dataset atualmente com {linha1} linhas e {coluna1} colunas.\\n'.replace(\"\\n\", \"<br />\"))\n\nprint(f'Antes da limpeza de dados faltantes, o data set tinha {linha} linhas e {coluna} colunas. A limpeza retirou {linha - linha1} linhas e {coluna - coluna1} colunas, ficando o dataset atualmente com {linha1} linhas e {coluna1} colunas.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.872779Z","iopub.execute_input":"2025-04-13T00:13:47.873536Z","iopub.status.idle":"2025-04-13T00:13:47.896778Z","shell.execute_reply.started":"2025-04-13T00:13:47.873506Z","shell.execute_reply":"2025-04-13T00:13:47.895765Z"}},"outputs":[{"name":"stdout","text":"Antes da limpeza de dados faltantes, o data set tinha 1094 linhas e 6 colunas. A limpeza retirou 0 linhas e 0 colunas, ficando o dataset atualmente com 1094 linhas e 6 colunas.\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"for coluna in df.columns:\n    if (df[coluna].dtype == 'int') or (df[coluna].dtype == 'float'):\n        Q1 = df[coluna].quantile(0.25)\n        Q3 = df[coluna].quantile(0.75)\n        IQR = Q3 - Q1\n        limite_inferior = Q1 - 1.5 * IQR\n        limite_superior = Q3 + 1.5 * IQR\n\n        contagem_inferiores = (df[coluna] < limite_inferior).sum()\n        contagem_superiores = (df[coluna] > limite_superior).sum()\n\n        df[coluna] = df[coluna].apply(\n            lambda x: limite_inferior if x < limite_inferior else \n                     (limite_superior if x > limite_superior else x))\n\npdf_gen.add_text(f\"A quantidade de outliers detectados nas variáveis quantitativas foram {contagem_inferiores + contagem_superiores}.\\nCom {contagem_inferiores} valores abaixo do limite inferior e {contagem_superiores} valores acima do limite superior, e todos eles foram substituidos pelos seus respectivos limites em cada coluna de dados quantitativos. \\n\".replace(\"\\n\", \"<br />\"))\n\nprint(f\"A quantidade de outliers detectados nas variáveis quantitativas foram {contagem_inferiores + contagem_superiores}.\\nCom {contagem_inferiores} valores abaixo do limite inferior e {contagem_superiores} valores acima do limite superior, e todos eles foram substituidos pelos seus respectivos limites em cada coluna de dados quantitativos. \\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:47.898184Z","iopub.execute_input":"2025-04-13T00:13:47.899173Z","iopub.status.idle":"2025-04-13T00:13:47.923053Z","shell.execute_reply.started":"2025-04-13T00:13:47.899144Z","shell.execute_reply":"2025-04-13T00:13:47.921927Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"A quantidade de outliers detectados nas variáveis quantitativas foram 26.\nCom 0 valores abaixo do limite inferior e 26 valores acima do limite superior, e todos eles foram substituidos pelos seus respectivos limites em cada coluna de dados quantitativos. \n\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"# Data Analysis","metadata":{}},{"cell_type":"code","source":"# Heatmaps\n\ndef safe_pearson(x, y):\n    \"\"\"Calcula Pearson apenas para variáveis numéricas\"\"\"\n    if pd.api.types.is_numeric_dtype(x) and pd.api.types.is_numeric_dtype(y):\n        return pearsonr(x, y)[0]\n    return np.nan\n\ndef safe_spearman(x, y):\n    \"\"\"Calcula Spearman para qualquer tipo após conversão\"\"\"\n    try:\n        return spearmanr(x, y).correlation\n    except:\n        return np.nan\n\ndef safe_mutual_info(x, y):\n    \"\"\"Calcula informação mútua de acordo com os tipos de dados\"\"\"\n    try:\n        if pd.api.types.is_numeric_dtype(y):\n            return mutual_info_regression(x.values.reshape(-1, 1), y)[0]\n        else:\n            return mutual_info_classif(x.values.reshape(-1, 1), y)[0]\n    except:\n        return np.nan\n\ndef calculate_correlations(df):\n    \"\"\"Calcula todas as matrizes de correlação\"\"\"\n    cols = df.columns\n    n = len(cols)\n    \n    pearson = np.zeros((n, n))\n    spearman = np.zeros((n, n))\n    mi = np.zeros((n, n))\n    \n    # Pré-processamento para Spearman/MI\n    df_encoded = df.copy()\n    for col in df.select_dtypes(include=['object', 'category']):\n        df_encoded[col] = LabelEncoder().fit_transform(df[col])\n    \n    for i in range(n):\n        for j in range(n):\n            pearson[i, j] = safe_pearson(df[cols[i]], df[cols[j]])\n            spearman[i, j] = safe_spearman(df_encoded[cols[i]], df_encoded[cols[j]])\n            mi[i, j] = safe_mutual_info(df_encoded[cols[i]], df_encoded[cols[j]])\n    \n    return {\n        'Pearson': pd.DataFrame(pearson, index=cols, columns=cols),\n        'Spearman': pd.DataFrame(spearman, index=cols, columns=cols),\n        'Mutual_Info': pd.DataFrame(mi, index=cols, columns=cols)\n    }\n\ndef plot_correlation_heatmaps(df):\n    \"\"\"Gera e exibe os heatmaps sem retornar valores\"\"\"\n    correlations = calculate_correlations(df)\n    \n    # Heatmap Pearson\n    fig_pearson = go.Figure(go.Heatmap(\n        z=correlations['Pearson'],\n        x=df.columns,\n        y=df.columns,\n        zmin=-1,\n        zmax=1,\n        colorscale='RdBu',\n        text=np.round(correlations['Pearson'], 2),\n        texttemplate=\"%{text}\"\n    ))\n    fig_pearson.update_layout(title='Correlação Linear (Pearson)')\n    fig_pearson.show(renderer='iframe')\n\n    fig_pearson.write_image(\"heatmap_pearson.png\", scale=2)\n\n    pdf_gen.add_image(\"heatmap_pearson.png\")\n    \n    \n    # Heatmap Spearman\n    fig_spearman = go.Figure(go.Heatmap(\n        z=correlations['Spearman'],\n        x=df.columns,\n        y=df.columns,\n        zmin=-1,\n        zmax=1,\n        colorscale='RdBu',\n        text=np.round(correlations['Spearman'], 2),\n        texttemplate=\"%{text}\"\n    ))\n    fig_spearman.update_layout(title='Correlação Monotônica (Spearman)')\n    fig_spearman.show(renderer='iframe')\n\n    fig_spearman.write_image(\"heatmap_spearman.png\", scale=2)\n\n    pdf_gen.add_image(\"heatmap_spearman.png\")\n    \n    \n    # Heatmap Informação Mútua\n    fig_mi = go.Figure(go.Heatmap(\n        z=correlations['Mutual_Info'],\n        x=df.columns,\n        y=df.columns,\n        colorscale='Viridis',\n        text=np.round(correlations['Mutual_Info'], 2),\n        texttemplate=\"%{text}\"\n    ))\n    fig_mi.update_layout(title='Dependência Não-Linear (Informação Mútua)')\n    fig_mi.show(renderer='iframe')\n\n    fig_mi.write_image(\"heatmap_mi.png\", scale=2)\n\n    pdf_gen.add_image(\"heatmap_mi.png\")\n    ","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-13T00:13:47.924294Z","iopub.execute_input":"2025-04-13T00:13:47.924688Z","iopub.status.idle":"2025-04-13T00:13:47.950173Z","shell.execute_reply.started":"2025-04-13T00:13:47.924649Z","shell.execute_reply":"2025-04-13T00:13:47.948930Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"def analise_qualitativa(series):\n    \n    # unicos\n    pdf_gen.add_text(f\"\"\"Há {len(series.unique())} valores unicos dos quais são: \\n\n    {series.unique()}\n    \\n\"\"\".replace(\"\\n\", \"<br />\"))\n    \n    # moda\n    pdf_gen.add_text(f'''O que valor mais aparece (a moda) é \\n\n    {series.mode()}\n    \\n'''.replace(\"\\n\", \"<br />\"))\n\n    \n    # tabela de frequencia\n    \n    tabela_frequencia = pd.DataFrame(series.value_counts().reset_index())\n\n    tabela_frequencia.columns = [series.name, 'Frequência Simples (ni)']\n\n    tabela_frequencia['Frequência Relativa % (fi)'] = (tabela_frequencia['Frequência Simples (ni)'] / len(series)) * 100\n\n    tabela_frequencia['Frequência Acumulada (Ni)'] = tabela_frequencia['Frequência Simples (ni)'].cumsum()\n\n    tabela_frequencia['Frequência Relativa Acumulada % (Fi)'] = tabela_frequencia['Frequência Relativa % (fi)'].cumsum()\n    \n    tabela_frequencia_visual = tabela_frequencia.style.format({'Frequência Relativa % (fi)': '{:.2f}%', 'Frequência Relativa Acumulada % (Fi)': '{:.2f}%'})\n\n    pdf_gen.add_dataframe(tabela_frequencia_visual, style=False)\n\n    pdf_gen.add_break()\n\n    \n    # graficos\n\n        # pizza\n    fig_pie = px.pie(\n        tabela_frequencia,\n        names=series.name,\n        values='Frequência Relativa % (fi)',\n        title=f'Representação de cada {series.name}',\n        color_discrete_sequence=px.colors.qualitative.Pastel\n    )\n\n        # melhorar a formatação\n    fig_pie.update_traces(\n        textposition='outside',\n        textinfo='percent+label',\n        pull=[0.12, 0.12, 0.12]  # Destacar as três primeiras fatias\n    )\n    \n        # mostrar o gráfico\n    fig_pie.show(renderer='iframe')\n    \n        # salvar como imagem\n    fig_pie.write_image(\"grafico_pizza.png\", scale=2)\n\n    pdf_gen.add_image(\"grafico_pizza.png\")\n\n    # barras\n    fig_bar = px.bar(\n        tabela_frequencia,\n        x=series.name,\n        y='Frequência Relativa % (fi)',\n        title=f'Representação de cada {series.name}',\n        color=series.name,\n        color_discrete_sequence=px.colors.qualitative.Set2\n    )\n    \n        # personalizar o layout\n    fig_bar.update_layout(\n        xaxis_title=series.name,\n        yaxis_title='Frequência Relativa % (fi)',\n        showlegend=False,\n        hovermode='x'\n    )\n    \n        # adicionar valores nas barras\n    fig_bar.update_traces(\n        texttemplate='%{y}',\n        textposition='outside'\n    )\n    \n        # mostrar o gráfico\n    fig_bar.show(renderer='iframe')\n    \n        # salvar como imagem\n    fig_bar.write_image(\"grafico_barras.png\", scale=2)\n\n    pdf_gen.add_image(\"grafico_barras.png\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-13T00:13:47.951330Z","iopub.execute_input":"2025-04-13T00:13:47.951585Z","iopub.status.idle":"2025-04-13T00:13:47.977448Z","shell.execute_reply.started":"2025-04-13T00:13:47.951566Z","shell.execute_reply":"2025-04-13T00:13:47.976353Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"def analise_quantitativa(series):\n    \n    # media, moda, mediana\n    media = series.mean()\n    moda = series.median()\n    mediana = series.mode()\n\n    pdf_gen.add_text(f'''Os dados de {series.name} possuem:\\n\n    media: {media:.2f}\\n\n    moda: {moda:.2f}\\n\n    mediana: {mediana.iloc[0]:.2f}\\n\n    '''.replace(\"\\n\", \"<br />\"))\n\n\n    # tabela de frequência intervalar\n        \n        # calculando número de classes (Regra de Sturges)\n    n = len(series)\n    k = int(1 + 3.322 * np.log10(n)) if n > 0 else 5\n    if (k > 7):\n        k = 7\n    \n        # calculando amplitude\n    amplitude = series.max() - series.min()\n    \n        # calculando amplitude de cada classe\n    h = amplitude / k\n\n        # gerando os limites das classes\n    limites_inferiores = np.linspace(series.min(), series.max() - h, k)\n    limites_superiores = limites_inferiores + h\n    \n        # arredondando para melhor visualização\n    limites_inferiores = np.round(limites_inferiores, 2)\n    limites_superiores = np.round(limites_superiores, 2)\n\n        # formata os intervalos de classe\n    classes = [f\"{li:.0f} ⊢ {ls:.0f}\" for li, ls in zip(limites_inferiores, limites_superiores)]\n    \n        # calcula as frequências absolutas (ni)\n    frequencias = []\n    for li, ls in zip(limites_inferiores, limites_superiores):\n        freq = ((series >= li) & (series < ls)).sum()\n        frequencias.append(freq)\n    \n        # calcula os pontos médios (Xi)\n    pontos_medios = (limites_inferiores + limites_superiores) / 2\n    \n        # cria o DataFrame base\n    tabela = pd.DataFrame({\n        series.name: classes,\n        'Frequência (ni)': frequencias,\n    })\n    \n    \n        # calcula as demais colunas\n    tabela['Frequência Relativa % (fi)'] = np.round(tabela['Frequência (ni)'] / n, 4)\n    tabela['Frequência Relativa % (fi)'] = (tabela['Frequência Relativa % (fi)'] * 100).round(2)\n    tabela['Frequência Acumulada (Ni)'] = tabela['Frequência (ni)'].cumsum()\n    tabela['Frequência Relativa Acumulada % (Fi)'] = np.round(tabela['Frequência Acumulada (Ni)'] / n, 4)\n    tabela['Frequência Relativa Acumulada % (Fi)'] = (tabela['Frequência Relativa Acumulada % (Fi)'] * 100).round(2)\n    tabela['Ponto Médio da Classe (Xi)'] = np.round(pontos_medios, 2)\n    \n        # adiciona a porcentagem para facilitar leitura\n    tabela_visual = tabela.style.format({'Frequência Relativa % (fi)': '{:.2f}%', 'Frequência Relativa Acumulada % (Fi)': '{:.2f}%', 'Ponto Médio da Classe (Xi)': '{:.2f}'})\n    \n    pdf_gen.add_dataframe(tabela_visual, style=False)\n\n    pdf_gen.add_break()\n\n    \n    # dispersão\n    # desvio padrão e coeficiente de variação\n    desvio = series.std()\n        \n    pdf_gen.add_text(f\"Desvio padrão: \\n{desvio:.4f} \\n\\nCoeficiente de variação: \\n{(desvio/media)*100:.2f}%\\n\\n\".replace(\"\\n\", \"<br />\"))\n        \n    # interpretação\n    if desvio/media > 0.3:\n        pdf_gen.add_text(\"Os dados estão relativamente dispersos em relação à média\\n\".replace(\"\\n\", \"<br />\"))\n    else:\n        pdf_gen.add_text(\"Os dados estão relativamente concentrados em torno da média\\n\".replace(\"\\n\", \"<br />\"))\n\n\n    \n    # boxplot completo com estatísticas\n    fig = go.Figure()\n    \n    fig.add_trace(go.Box(\n        y=series,\n        name='Distribuição',\n        boxpoints='outliers',  # Mostra outliers individuais\n        marker_color='#1f77b4',\n        line_color='#1f77b4',\n        fillcolor='lightblue',\n        jitter=0.5,  # Espaçamento dos pontos\n        whiskerwidth=0.2,\n        hoverinfo='y+name'\n    ))\n    \n    # Adicionando estatísticas como anotações\n    stats = series.describe()\n    annotations = [\n        dict(\n            x=0.05,\n            y=stats['mean'],\n            xref='paper',\n            yref='y',\n            text=f'Média: {stats[\"mean\"]:.2f}',\n            showarrow=True,\n            arrowhead=1,\n            ax=-50\n        ),\n        dict(\n            x=0.05,\n            y=stats['50%'],\n            xref='paper',\n            yref='y',\n            text=f'Mediana: {stats[\"50%\"]:.2f}',\n            showarrow=True,\n            arrowhead=1,\n            ax=-50\n        )\n    ]\n    \n    fig.update_layout(\n        title=f'Boxplot of {series.name}',\n        yaxis_title='Valores',\n        showlegend=False,\n        annotations=annotations,\n        hovermode='y unified',\n        height=600\n    )\n    \n    fig.show(renderer='iframe')\n\n    fig.write_image(\"boxplot.png\", scale=2)\n\n    pdf_gen.add_image(\"boxplot.png\")\n\n\n\n    # simetria/assimetria\n\n        # configuração do tema\n    pio.templates.default = \"plotly_white\"\n    \n        # entrada dos dados \n    dados = series\n\n    media = float(dados.mean())  # Convertendo para float nativo\n    mediana = float(dados.median())\n    modas = dados.mode().values  # Array numpy com as modas\n\n    title = f\"Histogram of {series.name}\"\n\n    valores = dados\n\n     # Tentar adicionar KDE\n    fig = go.Figure()\n    \n    # Adicionar histograma\n    fig.add_trace(go.Histogram(\n        x=valores,\n        name='Histograma',\n        nbinsx=30,\n        marker_color='#1f77b4',\n        opacity=0.7,\n        histnorm='probability density',\n        hovertemplate='Intervalo: %{x:.2f}<br>Frequência: %{y:.4f}<extra></extra>'\n    ))\n    \n    # Adicionar curva KDE (se possível)\n    try:\n        if len(np.unique(valores)) > 1:  # Verifica se há variância\n            kde = gaussian_kde(valores)\n            x_kde = np.linspace(np.min(valores), np.max(valores), 500)\n            y_kde = kde(x_kde)\n            \n            fig.add_trace(go.Scatter(\n                x=x_kde, y=y_kde,\n                name='Densidade KDE',\n                line=dict(color='#ff7f0e', width=2),\n                hovertemplate='Valor: %{x:.2f}<br>Densidade: %{y:.4f}<extra></extra>'\n            ))\n        else:\n            pdf_gen.add_text(f\"Os dados de {series.name} são constantes\\n\".replace(\"\\n\", \"<br />\"))\n            raise ValueError(\"Dados constantes\")\n            \n    except Exception as e:\n        pdf_gen.add_text(f\"O KDE de {series.name} não pôde ser calculado.\\nMotivo:\\n{str(e)}\\n\".replace(\"\\n\", \"<br />\"))\n        print(f\"Aviso: Não foi possível calcular KDE - {str(e)}\")\n        \n    \n    # Posições verticais para as anotações (evitar sobreposição)\n    y_positions = {\n        'media': 0.9,\n        'mediana': 0.7,\n        'moda': 0.5\n    }\n    \n    # Adicionar linha da média\n    fig.add_vline(\n        x=media,\n        line=dict(color='red', dash='dash', width=2),\n        annotation_text=f'Média: {media:.2f}',\n        annotation_position=\"top right\",\n        annotation_y=y_positions['media'],\n        annotation_yanchor=\"top\",\n        annotation_font=dict(color='red')\n    )\n    \n    # Adicionar linha da mediana\n    fig.add_vline(\n        x=mediana,\n        line=dict(color='green', width=2),\n        annotation_text=f'Mediana: {mediana:.2f}',\n        annotation_position=\"bottom right\",\n        annotation_y=y_positions['mediana'],\n        annotation_yanchor=\"top\",\n        annotation_font=dict(color='green')\n    )\n    \n    # Adicionar linhas para moda(s)\n    for i, moda in enumerate(modas):\n        fig.add_vline(\n            x=moda,\n            line=dict(color='purple', dash='dot', width=2),\n            annotation_text=f'Moda {i+1}: {moda:.2f}' if len(modas) > 1 else f'Moda: {moda:.2f}',\n            annotation_position=\"top left\",\n            annotation_y=y_positions['moda'] - (i*0.1),  # Deslocamento para múltiplas modas\n            annotation_yanchor=\"top\",\n            annotation_font=dict(color='purple')\n        )\n    \n    # Layout final\n    fig.update_layout(\n        title=title,\n        xaxis_title='Valores',\n        yaxis_title='Densidade',\n        hovermode='x unified',\n        showlegend=True,\n        legend=dict(\n            orientation=\"h\",\n            yanchor=\"bottom\",\n            y=1.02,\n            xanchor=\"right\",\n            x=1\n        ),\n        height=600,\n        margin=dict(t=50, b=50)\n    )\n    \n    fig.show(renderer='iframe')\n\n    fig.write_image(\"histograma.png\", scale=2)      \n        \n    pdf_gen.add_image(\"histograma.png\")       \n        ","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-13T00:13:47.978911Z","iopub.execute_input":"2025-04-13T00:13:47.979265Z","iopub.status.idle":"2025-04-13T00:13:48.008302Z","shell.execute_reply.started":"2025-04-13T00:13:47.979152Z","shell.execute_reply":"2025-04-13T00:13:48.007047Z"}},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":"## Analysis functions","metadata":{}},{"cell_type":"code","source":"for coluna in df.columns:\n    if (df[coluna].dtype == 'string'):\n        pdf_gen.add_header(f'''\\n{' ANALISE QUALITATIVA '} \\n'''.replace(\"\\n\", \"<br />\"))\n        analise_qualitativa(df[coluna])\n\n    elif(df[coluna].dtype == ('float' or 'int')):\n        pdf_gen.add_header(f'''\\n{' ANALISE QUANTITATIVA '} \\n'''.replace(\"\\n\", \"<br />\"))\n        analise_quantitativa(df[coluna])\n\n\npdf_gen.add_header(f'''\\n{' CORRELAÇÕES COM MAPAS DE CALOR '} \\n'''.replace(\"\\n\", \"<br />\"))\nplot_correlation_heatmaps(df)","metadata":{"trusted":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"execution":{"iopub.status.busy":"2025-04-13T00:13:48.009491Z","iopub.execute_input":"2025-04-13T00:13:48.009974Z","iopub.status.idle":"2025-04-13T00:13:53.630529Z","shell.execute_reply.started":"2025-04-13T00:13:48.009937Z","shell.execute_reply":"2025-04-13T00:13:53.629259Z"},"collapsed":true},"outputs":[{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"620\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"620\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"620\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"620\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<iframe\n    scrolling=\"no\"\n    width=\"100%\"\n    height=\"545px\"\n    src=\"iframe_figures/figure_64.html\"\n    frameborder=\"0\"\n    allowfullscreen\n></iframe>\n"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"pdf_file = pdf_gen.generate_pdf(\"analise_descritiva.pdf\")\nprint(f\"PDF gerado com sucesso: {pdf_file}\")\n\n# Opcional: fazer download no Kaggle\nfrom IPython.display import FileLink\nFileLink(pdf_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T00:13:53.631681Z","iopub.execute_input":"2025-04-13T00:13:53.632112Z","iopub.status.idle":"2025-04-13T00:13:55.528348Z","shell.execute_reply.started":"2025-04-13T00:13:53.632076Z","shell.execute_reply":"2025-04-13T00:13:55.526680Z"}},"outputs":[{"name":"stdout","text":"PDF gerado com sucesso: analise_descritiva.pdf\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/analise_descritiva.pdf","text/html":"<a href='analise_descritiva.pdf' target='_blank'>analise_descritiva.pdf</a><br>"},"metadata":{}}],"execution_count":65},{"cell_type":"markdown","source":"pdf_gen.add_header(f'''\\n{' ANÁLISES BIMODAIS '} \\n'''.replace(\"\\n\", \"<br />\"))\nanalise_bimodal(df.iloc[:, 1:])\n\n# bimodal analysis\n\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom scipy.stats import pearsonr\nfrom datetime import datetime\n\nsns.set_palette(\"deep\") \n\ndef analise_bimodal(df):\n    \"\"\"\n    Analisa combinações bimodais entre colunas de um DataFrame e gera visualizações específicas.\n    \n    Parâmetros:\n    df (pd.DataFrame): DataFrame com os dados a serem analisados\n    \"\"\"\n    \n    # Verificar tipos de cada coluna\n    col_types = {}\n    for col in df.columns:\n        if pd.api.types.is_numeric_dtype(df[col]):\n            col_types[col] = 'quantitativo'\n        elif pd.api.types.is_datetime64_any_dtype(df[col]):\n            col_types[col] = 'data'\n        else:\n            col_types[col] = 'qualitativo'\n    \n    # Percorrer todas as combinações únicas de colunas\n    cols = df.columns.tolist()\n    for i in range(len(cols)):\n        for j in range(i + 1, len(cols)):\n            col1 = cols[i]\n            col2 = cols[j]\n            type1 = col_types[col1]\n            type2 = col_types[col2]\n            \n            print(f\"\\nAnalisando combinação: {col1} ({type1}) vs {col2} ({type2})\")\n            pdf_gen.add_text(f'''\\n\n            Analisando combinação: \\n\n            {col1} ({type1}) vs {col2} ({type2})\\n\n            '''.replace(\"\\n\", \"<br />\"))\n            \n            # Qualitativo vs Qualitativo\n            if type1 == 'qualitativo' and type2 == 'qualitativo':\n                analise_qual_qual(df, col1, col2)\n            \n            # Qualitativo vs Quantitativo\n            elif (type1 == 'qualitativo' and type2 == 'quantitativo') or \\\n                 (type1 == 'quantitativo' and type2 == 'qualitativo'):\n                if type1 == 'quantitativo':  # Garantir ordem qualitativo -> quantitativo\n                    col1, col2 = col2, col1\n                analise_qual_quant(df, col1, col2)\n            \n            # Quantitativo vs Quantitativo\n            elif type1 == 'quantitativo' and type2 == 'quantitativo':\n                analise_quant_quant(df, col1, col2)\n            \n            # Qualitativo vs Data\n            elif (type1 == 'qualitativo' and type2 == 'data') or \\\n                 (type1 == 'data' and type2 == 'qualitativo'):\n                if type1 == 'data':  # Garantir ordem qualitativo -> data\n                    col1, col2 = col2, col1\n                analise_qual_data(df, col1, col2)\n            \n            # Quantitativo vs Data\n            elif (type1 == 'quantitativo' and type2 == 'data') or \\\n                 (type1 == 'data' and type2 == 'quantitativo'):\n                if type1 == 'data':  # Garantir ordem quantitativo -> data\n                    col1, col2 = col2, col1\n                analise_quant_data(df, col1, col2)\n            \n            else:\n                print(f\"Combinação não tratada: {type1} vs {type2}\")\n                pdf_gen.add_text(f'''\n                Combinação não tratada: \\n\n                {col1} ({type1}) vs {col2} ({type2})\\n\n                '''.replace(\"\\n\", \"<br />\"))\n\ndef analise_qual_qual(df, col1, col2):\n    \"\"\"Análise para duas variáveis qualitativas\"\"\"\n    # Tabela de frequência\n    freq = pd.crosstab(df[col1], df[col2], margins=True)\n    freq_rel = pd.crosstab(df[col1], df[col2], normalize='all') * 100\n    \n    print(\"\\nTabela de Frequência Absoluta:\")\n    display(freq)\n\n    pdf_gen.add_dataframe(freq, style=False)\n\n    pdf_gen.add_break()\n    \n    print(\"\\nTabela de Frequência Relativa (%):\")\n    display(freq_rel.style.format(\"{:.2f}%\"))\n\n    pdf_gen.add_dataframe(freq_rel.style.format(\"{:.2f}%\"), style=False)\n\n    pdf_gen.add_break()\n    \n    # Gráfico de barras agrupadas\n    fig = px.bar(df, x=col1, color=col2, barmode='group',\n                 title=f\"Distribuição de {col1} por {col2}\")\n    fig.show(renderer='iframe')\n\n    fig.write_image(\"barplot.png\", scale=2)\n\n    pdf_gen.add_image(\"barplot.png\")\n\ndef analise_qual_quant(df, col_qual, col_quant):\n    \"\"\"Análise para variável qualitativa vs quantitativa\"\"\"\n    # Histogramas lado a lado\n    fig = px.histogram(df, x=col_quant, color=col_qual, marginal=\"rug\",\n                       nbins=30, barmode='overlay', opacity=0.7,\n                       title=f\"Distribuição de {col_quant} por {col_qual}\")\n    fig.update_layout(bargap=0.1)\n    fig.show(renderer='iframe')\n\n    fig.write_image(\"histogram.png\", scale=2)\n\n    pdf_gen.add_image(\"histogram.png\")\n    \n    # Boxplot para comparação\n    fig = px.box(df, x=col_qual, y=col_quant, color=col_qual,\n                 title=f\"Distribuição de {col_quant} por {col_qual}\")\n    fig.show(renderer='iframe')\n\n    fig.write_image(\"boxplot.png\", scale=2)\n\n    pdf_gen.add_image(\"boxplot.png\")\n\ndef analise_quant_quant(df, col1, col2):\n    \"\"\"Análise para duas variáveis quantitativas\"\"\"\n    # Scatter plot\n    fig = px.scatter(df, x=col1, y=col2, trendline=\"ols\",\n                     title=f\"Relação entre {col1} e {col2}\")\n    \n    # Calcular correlação\n    corr, p_valor = pearsonr(df[col1].dropna(), df[col2].dropna())\n    \n    # Remover linha de tendência se não houver correlação significativa\n    if p_valor > 0.05:\n        fig.data = [fig.data[0]]  # Mantém apenas o scatter\n        fig.update_layout(annotations=[], title=f\"Relação entre {col1} e {col2} (sem correlação significativa)\")\n    \n    fig.add_annotation(text=f\"Correlação: {corr:.2f} (p-valor: {p_valor:.3f})\",\n                       xref=\"paper\", yref=\"paper\",\n                       x=0.05, y=0.95, showarrow=False)\n    fig.show(renderer='iframe')\n\n    fig.write_image(\"scatterlineplot.png\", scale=2)\n\n    pdf_gen.add_image(\"scatterlineplot.png\")\n\ndef analise_qual_data(df, col_qual, col_data):\n    \"\"\"Análise para variável qualitativa vs data\"\"\"\n    # Determinar granularidade temporal\n    n_anos = df[col_data].dt.year.nunique()\n    \n    if n_anos >= 3:\n        # Agrupar por ano\n        df_temp = df.copy()\n        df_temp['Ano'] = df_temp[col_data].dt.year\n        df_grouped = df_temp.groupby(['Ano', col_qual]).size().reset_index(name='Contagem')\n        \n        fig = px.line(df_grouped, x='Ano', y='Contagem', color=col_qual,\n                      title=f\"Evolução Temporal de {col_qual} (por Ano)\")\n    else:\n        # Agrupar por mês-ano\n        df_temp = df.copy()\n        df_temp['Mês-Ano'] = df_temp[col_data].dt.to_period('M').dt.to_timestamp()\n        df_grouped = df_temp.groupby(['Mês-Ano', col_qual]).size().reset_index(name='Contagem')\n        \n        fig = px.line(df_grouped, x='Mês-Ano', y='Contagem', color=col_qual,\n                      title=f\"Evolução Temporal de {col_qual} (por Mês)\")\n    \n    fig.update_traces(mode='lines+markers')\n    fig.show(renderer='iframe')\n\n    fig.write_image(\"lineplot.png\", scale=2)\n\n    pdf_gen.add_image(\"lineplot.png\")\n\ndef analise_quant_data(df, col_quant, col_data):\n    \"\"\"Análise para variável quantitativa vs data\"\"\"\n    # Determinar granularidade temporal\n    n_anos = df[col_data].dt.year.nunique()\n    \n    if n_anos >= 3:\n        # Agrupar por ano\n        df_temp = df.copy()\n        df_temp['Ano'] = df_temp[col_data].dt.year\n        df_grouped = df_temp.groupby('Ano')[col_quant].mean().reset_index()\n        \n        fig = px.line(df_grouped, x='Ano', y=col_quant,\n                      title=f\"Série Temporal de {col_quant} (por Ano)\")\n    else:\n        # Agrupar por mês-ano\n        df_temp = df.copy()\n        df_temp['Mês-Ano'] = df_temp[col_data].dt.to_period('M').dt.to_timestamp()\n        df_grouped = df_temp.groupby('Mês-Ano')[col_quant].mean().reset_index()\n        \n        fig = px.line(df_grouped, x='Mês-Ano', y=col_quant,\n                      title=f\"Série Temporal de {col_quant} (por Mês)\")\n    \n    # Adicionar média móvel\n    fig.add_trace(go.Scatter(\n        x=df_grouped.iloc[:, 0],\n        y=df_grouped[col_quant].rolling(3, min_periods=1).mean(),\n        name='Média Móvel (3 períodos)',\n        line=dict(color='red', dash='dash')\n    ))\n    \n    fig.update_traces(mode='lines+markers')\n    fig.update_xaxes(rangeslider_visible=True)\n    fig.show(renderer='iframe')\n\n    fig.write_image(\"scatterplot.png\", scale=2)\n\n    pdf_gen.add_image(\"scatterplot.png\")","metadata":{"jupyter":{"source_hidden":true}}}]}